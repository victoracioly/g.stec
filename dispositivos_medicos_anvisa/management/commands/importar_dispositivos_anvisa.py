# Importa bibliotecas necess√°rias
import os
import requests
import pandas as pd
from io import BytesIO
from datetime import date, datetime
from django.core.management.base import BaseCommand
from dispositivos_medicos_anvisa.models import DispositivoMedicoAnvisa
from django.db import transaction  # Importado para transa√ß√µes at√¥micas


class Command(BaseCommand):
    help = 'Importa a lista de dispositivos m√©dicos a partir de um CSV p√∫blico no S3'

    def handle(self, *args, **kwargs):
        url_csv = 'https://gstec-anvisa.s3.sa-east-1.amazonaws.com/dispositivos.csv'
        self.stdout.write(f'üìÖ Baixando CSV diretamente do S3: {url_csv}')

        # Caminho do CSV salvo localmente
        base_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.join(base_dir, '..', '..', 'data')
        os.makedirs(data_dir, exist_ok=True)
        csv_path = os.path.join(data_dir, 'dispositivos_raw.csv')

        csv_data = None
        try:
            response = requests.get(url_csv, timeout=60)
            response.raise_for_status()  # Lan√ßa um erro para status HTTP ruins (4xx, 5xx)
            with open(csv_path, 'wb') as f:
                f.write(response.content)
            csv_data = BytesIO(response.content)
            self.stdout.write('‚úÖ Download realizado com sucesso.')
        except Exception as e:
            self.stderr.write(f"‚ö†Ô∏è Erro ao baixar, tentando usar o √∫ltimo CSV salvo. {e}")
            if not os.path.exists(csv_path):
                self.stderr.write("‚ùå Nenhum CSV salvo encontrado. N√£o √© poss√≠vel prosseguir.")
                return  # Interrompe a execu√ß√£o se n√£o houver CSV
            with open(csv_path, 'rb') as f:
                csv_data = BytesIO(f.read())
            self.stdout.write('‚úÖ Usando CSV salvo localmente.')

        if csv_data is None:  # Garante que temos dados para processar
            self.stderr.write("‚ùå N√£o foi poss√≠vel obter dados do CSV de nenhuma fonte.")
            return

        try:
            # Ao ler o CSV, j√° podemos usar converters para algumas colunas
            df = pd.read_csv(
                csv_data,
                sep=';',
                encoding='latin1',
                dtype=str,  # Lemos tudo como string para ter controle total na limpeza
                converters={'NUMERO_REGISTRO_CADASTRO': lambda x: str(x).strip()}
            )
            self.stdout.write(f'‚úÖ CSV lido com sucesso. Total de linhas: {len(df)}')
        except Exception as e:
            self.stderr.write(f'‚ùå Erro ao ler o CSV: {e}')
            return

        df.columns = df.columns.str.strip()  # Remove espa√ßos dos nomes das colunas
        colunas_esperadas = [
            'NUMERO_REGISTRO_CADASTRO', 'NUMERO_PROCESSO', 'NOME_TECNICO',
            'CLASSE_RISCO', 'NOME_COMERCIAL', 'CNPJ_DETENTOR_REGISTRO_CADASTRO',
            'DETENTOR_REGISTRO_CADASTRO', 'NOME_FABRICANTE', 'NOME_PAIS_FABRIC',
            'DT_PUB_REGISTRO_CADASTRO', 'VALIDADE_REGISTRO_CADASTRO', 'DT_ATUALIZACAO_DADO'
        ]

        # Verifica se todas as colunas esperadas est√£o presentes
        faltando = [col for col in colunas_esperadas if col not in df.columns]
        if faltando:
            self.stderr.write(f"‚ùå Erro: Colunas ausentes no CSV: {', '.join(faltando)}")
            return

        # --- Fun√ß√µes de Limpeza Otimizadas para Pandas Series ---
        def limpar_str_serie(serie):
            # Converte para string, remove espa√ßos em branco e trata valores vazios/NaN
            return serie.fillna('').astype(str).str.strip()

        def limpar_numero_registro_serie(serie):
            # Aplica zfill ap√≥s a limpeza b√°sica de string, garantindo 14 d√≠gitos
            return serie.fillna('').astype(str).str.strip().str.zfill(14)

        def limpar_data_serie(serie):
            # 1. Trata valores que s√£o intrinsecamente "nulos" ou problem√°ticos
            serie_processada = serie.astype(str).str.lower().str.strip().replace(
                ["00/00", "n/a", "nan", "vigente", ""], pd.NaT
            )

            # 2. Tenta converter para datetime, com errors=coerce para transformar falhas em NaT
            # Tenta primeiro o formato com horas, depois infer√™ncia com dayfirst=True
            converted_dates = pd.to_datetime(serie_processada, format="%m/%d/%Y %H:%M:%S", errors="coerce")

            # Para os que ainda s√£o NaT ap√≥s a primeira tentativa, tenta com dayfirst=True
            mask_nat = pd.isna(converted_dates)
            converted_dates.loc[mask_nat] = pd.to_datetime(serie_processada.loc[mask_nat], errors="coerce",
                                                           dayfirst=True)

            # 3. Garante que todos os NaT s√£o preenchidos com um Timestamp padr√£o e convertidos para datetime.date
            # Converte tudo para datetime64[ns] (Timestamps). NaT permanece NaT.
            series_of_timestamps = pd.to_datetime(converted_dates, errors='coerce')

            # Preenche os NaT com um Timestamp para manter o tipo da s√©rie
            # Use uma data padr√£o DENTRO DO LIMITE DO PANDAS (ex: 2100-01-01) para evitar OverflowError
            default_date_timestamp = pd.Timestamp(date(2100, 1, 1))
            final_dates_filled = series_of_timestamps.fillna(default_date_timestamp)

            # Finalmente, converte a Series de Timestamps para Series de datetime.date
            return final_dates_filled.dt.date

        self.stdout.write('‚ú® Aplicando fun√ß√µes de limpeza e padroniza√ß√£o ao DataFrame...')

        # Remove duplicatas do DataFrame com base no 'NUMERO_REGISTRO_CADASTRO'
        total_linhas_antes_duplicatas = len(df)
        df.drop_duplicates(subset=['NUMERO_REGISTRO_CADASTRO'], keep='first', inplace=True)
        total_linhas_depois_duplicatas = len(df)
        if total_linhas_antes_duplicatas > total_linhas_depois_duplicatas:
            self.stdout.write(self.style.WARNING(
                f'‚ö†Ô∏è {total_linhas_antes_duplicatas - total_linhas_depois_duplicatas} duplicatas de NUMERO_REGISTRO_CADASTRO removidas do CSV.'))

        # Aplica a limpeza para o n√∫mero de registro
        df['NUMERO_REGISTRO_CADASTRO'] = limpar_numero_registro_serie(df['NUMERO_REGISTRO_CADASTRO'])

        # APLICA A LIMPEZA DE DATA APENAS PARA OS CAMPOS QUE S√ÉO DateField NO SEU MODELO
        df['DT_PUB_REGISTRO_CADASTRO'] = limpar_data_serie(df['DT_PUB_REGISTRO_CADASTRO'])
        df['DT_ATUALIZACAO_DADO'] = limpar_data_serie(df['DT_ATUALIZACAO_DADO'])

        # O campo 'VALIDADE_REGISTRO_CADASTRO' √© CharField no seu models.py,
        # ent√£o ele deve ser limpo como uma string.
        df['VALIDADE_REGISTRO_CADASTRO'] = limpar_str_serie(df['VALIDADE_REGISTRO_CADASTRO'])

        # Aplica limpeza gen√©rica para as demais colunas de texto esperadas
        for col in colunas_esperadas:
            # Exclui as colunas j√° tratadas (NUMERO_REGISTRO_CADASTRO, e as 3 colunas de data/string)
            if col not in ['NUMERO_REGISTRO_CADASTRO', 'DT_PUB_REGISTRO_CADASTRO', 'DT_ATUALIZACAO_DADO',
                           'VALIDADE_REGISTRO_CADASTRO']:
                df[col] = limpar_str_serie(df[col])

        self.stdout.write('‚úÖ Limpeza do DataFrame conclu√≠da.')

        registros_sucesso_preparacao = 0  # Conta quantos objetos foram preparados com sucesso do CSV
        registros_erro_preparacao = 0  # Conta erros na fase de prepara√ß√£o do objeto
        objetos_para_inserir = []  # Lista para armazenar objetos DispositivoMedicoAnvisa do CSV

        log_erros_path = 'log_erros_importacao.txt'
        # Abre o arquivo de log para escrita, garantindo que ele esteja aberto durante as opera√ß√µes de DB
        with open(log_erros_path, 'w', encoding='utf-8') as log_file:
            log_file.write("LOG DE ERROS DE IMPORTA√á√ÉO\n\n")

            self.stdout.write('üîÑ Preparando objetos do Django a partir do DataFrame...')
            # --- itertuples() para melhor performance ---
            for row in df.itertuples(name='DispositivoRow'):
                # O 'row.Index' aqui ser√° o √≠ndice original do DataFrame, e 'row.COLUNA' ser√° o valor da coluna.

                # Reduz a frequ√™ncia do log de progresso para grandes datasets
                if row.Index % 500 == 0:
                    self.stdout.write(f"üîÑ Processando linha {row.Index}/{len(df)}...")

                    # --- Acesso aos dados da linha de row['COLUNA'] para row.COLUNA ---
                numero = row.NUMERO_REGISTRO_CADASTRO
                # Usar str(numero).strip() caso o campo venha como NaN/None
                if not numero or str(numero).strip() == '':
                    registros_erro_preparacao += 1
                    # N√£o podemos usar row.to_dict() com namedtuple, ent√£o formatamos manualmente
                    msg = f"‚ö†Ô∏è Linha {row.Index} ignorada - N√∫mero de registro vazio ap√≥s limpeza. Conte√∫do: {row}\n"
                    self.stderr.write(msg)
                    log_file.write(msg)
                    continue

                try:
                    obj = DispositivoMedicoAnvisa(
                        numero_registro_cadastro=numero,
                        numero_processo=row.NUMERO_PROCESSO,
                        nome_tecnico=row.NOME_TECNICO,
                        classe_risco=row.CLASSE_RISCO,
                        nome_comercial=row.NOME_COMERCIAL,
                        cnpj_detentor_registro=row.CNPJ_DETENTOR_REGISTRO_CADASTRO,
                        detentor_registro=row.DETENTOR_REGISTRO_CADASTRO,
                        nome_fabricante=row.NOME_FABRICANTE,
                        nome_pais_fabricante=row.NOME_PAIS_FABRIC,
                        data_publicacao_registro=row.DT_PUB_REGISTRO_CADASTRO,
                        validade_registro=row.VALIDADE_REGISTRO_CADASTRO,
                        data_atualizacao=row.DT_ATUALIZACAO_DADO,
                    )
                    objetos_para_inserir.append(obj)
                    registros_sucesso_preparacao += 1
                except Exception as e:
                    registros_erro_preparacao += 1
                    msg = f"‚ùå Erro ao preparar objeto da linha {row.Index} - Registro '{numero}': {e}\n"
                    self.stderr.write(msg)
                    log_file.write(msg)

            self.stdout.write('üì¶ Zerando banco e salvando novos objetos em massa...')

            registros_criados_db = 0
            registros_erro_db = 0

            with transaction.atomic():
                # PASSO CR√çTICO: ZERAR A TABELA ANTES DE INSERIR NOVOS DADOS
                self.stdout.write(self.style.WARNING("üóëÔ∏è Apagando todos os registros existentes da tabela..."))
                DispositivoMedicoAnvisa.objects.all().delete()
                self.stdout.write(self.style.SUCCESS("‚úÖ Registros existentes apagados."))

                # APENAS bulk_create AGORA (todos s√£o "novos" ap√≥s a exclus√£o)
                if objetos_para_inserir:
                    self.stdout.write(
                        f'üöÄ Iniciando cria√ß√£o em massa de {len(objetos_para_inserir)} registros em lotes (batch_size=500)...')
                    try:
                        created_objects = DispositivoMedicoAnvisa.objects.bulk_create(objetos_para_inserir,
                                                                                      batch_size=500,
                                                                                      ignore_conflicts=False)
                        registros_criados_db = len(created_objects)
                        self.stdout.write(self.style.SUCCESS(f'‚úÖ {registros_criados_db} novos registros criados.'))
                    except Exception as e:
                        registros_erro_db += len(objetos_para_inserir)
                        msg = f"‚ùå Erro em massa ao criar registros: {e}\n"
                        self.stderr.write(msg)
                        log_file.write(msg)
                else:
                    self.stdout.write(self.style.WARNING("‚ö†Ô∏è Nenhuns objetos para criar ap√≥s a prepara√ß√£o do CSV."))

            self.stdout.write(self.style.SUCCESS('‚úÖ Opera√ß√µes de banco de dados conclu√≠das.'))

        # As contagens finais e mensagens de sucesso/erro s√£o exibidas ap√≥s o 'with open'
        total_linhas_csv = total_linhas_depois_duplicatas
        total_banco = DispositivoMedicoAnvisa.objects.count()  # Contagem final do banco

        total_processado_com_sucesso_db = registros_criados_db
        total_erros_geral = registros_erro_preparacao + registros_erro_db

        self.stdout.write(self.style.SUCCESS('‚úÖ Importa√ß√£o finalizada.'))
        self.stdout.write(self.style.WARNING(f'Total de linhas √∫nicas no CSV processadas: {total_linhas_csv}'))
        self.stdout.write(self.style.WARNING(f'Total de registros no banco de dados (ap√≥s opera√ß√£o): {total_banco}'))
        self.stdout.write(
            self.style.SUCCESS(f'‚úÖ Registros criados no DB: {total_processado_com_sucesso_db}'))
        self.stdout.write(self.style.ERROR(f'‚ùå Registros com erro (total): {total_erros_geral} (ver {log_erros_path})'))
        self.stdout.write(self.style.SUCCESS(
            f'Total de linhas do CSV tentadas (pr√©-processamento): {registros_sucesso_preparacao + registros_erro_preparacao}'))